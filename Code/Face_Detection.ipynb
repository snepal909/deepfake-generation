{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "name": "Face Detection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "automated-beads",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c04362b3-0f93-4fe0-9a50-f8dfe991a280"
      },
      "source": [
        "!pip3 install face_recognition\n",
        "import face_recognition\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Rectangle\n",
        "import os\n",
        "import cv2\n",
        "import pathlib"
      ],
      "id": "automated-beads",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: face_recognition in /usr/local/lib/python3.7/dist-packages (1.3.0)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (7.1.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from face_recognition) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from face_recognition) (1.19.5)\n",
            "Requirement already satisfied: face-recognition-models>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (0.3.0)\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (19.18.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "later-landing"
      },
      "source": [
        "def extractImages(fileName, directory, output_directory, frame_every=1):\n",
        "    print(fileName)\n",
        "    pathOut = output_directory + \"/\" + fileName[0:-4] + \"/\"\n",
        "    if not os.path.exists(pathOut):\n",
        "        os.makedirs(pathOut)\n",
        "    print(pathOut)\n",
        "    count = 0\n",
        "    frame_count = 1\n",
        "    vidcap = cv2.VideoCapture(directory + \"/\" + fileName)\n",
        "    success,image = vidcap.read()\n",
        "    success = True\n",
        "    while success:\n",
        "        # vidcap.set(cv2.CAP_PROP_POS_MSEC,(count*1000))    # added this line\n",
        "        success,image = vidcap.read()\n",
        "        frame_count += 1\n",
        "\n",
        "        if success and (frame_count % frame_every == 0):\n",
        "            \n",
        "#             print ('Read a new frame: ', success)\n",
        "            frameName = pathOut + \"frame%04d.jpg\" % count\n",
        "            if count % 500 == 0:\n",
        "                print(frameName)\n",
        "\n",
        "            cv2.imwrite(frameName, image)     # save frame as JPEG file\n",
        "            count += 1\n",
        "        \n",
        "        "
      ],
      "id": "later-landing",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgtOUt1Ack46",
        "outputId": "3b724435-8b68-43dc-aa58-118e3fa6f53f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "qgtOUt1Ack46",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNhUyuq4lKvB"
      },
      "source": [
        "import numpy as np\n",
        "import PIL\n",
        "from tqdm import tqdm\n",
        "\n",
        "def load_images(imageDir):\n",
        "  imgs = []\n",
        "  for filename in os.listdir(imageDir):\n",
        "    if filename.endswith(\".jpg\"):\n",
        "      imgs.append((filename, np.array(PIL.Image.open(imageDir + filename))))\n",
        "  return imgs\n",
        "\n",
        "def num_images(imageDir):\n",
        "  count = 0\n",
        "  for filename in os.listdir(imageDir):\n",
        "    if filename.endswith(\".jpg\"):\n",
        "      count += 1\n",
        "  return count\n",
        "\n",
        "\"\"\"\n",
        "    Parameters: \n",
        "        - imageDir: the file path for the image directory extract the faces from\n",
        "        - face_encoder: the face encoder we want to compare to see if we have extracted the correct face\n",
        "\"\"\"\n",
        "def singleFaceExtracterWithExtraPixels(imageDir, directory, face_encoder, padding=0, mode='train', batch_size=128):\n",
        "    \n",
        "    pathOut = directory +'/'+imageDir[:-1]+'-face-crop/'\n",
        "    if not os.path.exists(pathOut):\n",
        "        os.makedirs(pathOut)\n",
        "    print(pathOut)\n",
        "    count = 0\n",
        "\n",
        "    if mode == 'test':\n",
        "      f = open(pathOut + \"frame_list.txt\", \"w\")\n",
        "      f.write(\"frame_number, top, right, bottom, left, height, width\\n\")\n",
        "      f.close()\n",
        "\n",
        "    # print('here')\n",
        "    # lst = load_images(directory +'/'+imageDir)\n",
        "    length = num_images(directory +'/'+imageDir)\n",
        "    # print('failed')\n",
        "\n",
        "    frame_count_load = 0\n",
        "    frame_count_compute = 0\n",
        "\n",
        "    print(length)\n",
        "    print(batch_size)\n",
        "\n",
        "    for index in tqdm(range((length // batch_size) + 1), position=0, leave=True):\n",
        "\n",
        "        images = []\n",
        "        filenames = []\n",
        "\n",
        "        for index2 in range(batch_size):\n",
        "            if frame_count_load < length:\n",
        "                filename = \"frame%04d.jpg\" % frame_count_load\n",
        "                path = directory + '/' + imageDir + filename\n",
        "                images.append(np.array(PIL.Image.open(path)))\n",
        "                filenames.append(filename)\n",
        "                frame_count_load += 1\n",
        "        # filename, image = lst[index]\n",
        "        # makes sure there is only one face in the image\n",
        "\n",
        "        outputs = face_recognition.batch_face_locations(images, batch_size=batch_size)\n",
        "\n",
        "        # Runs batch_size number of times\n",
        "        for image_idx, output in enumerate(outputs):\n",
        "            filename = \"frame%04d.jpg\" % frame_count_compute\n",
        "            image = images[image_idx]\n",
        "            frame_count_compute += 1\n",
        "\n",
        "            if len(output) == 1:\n",
        "                top, right, bottom, left = output[0]\n",
        "                cropped_face = image[top - padding:bottom + padding,left - padding:right + padding]\n",
        "\n",
        "                try:\n",
        "                  cropped_encoding = face_recognition.face_encodings(cropped_face)[0]\n",
        "                except IndexError as e:\n",
        "                  print(filename)\n",
        "                  continue\n",
        "                \n",
        "                # makes sure it is the face that was encoded\n",
        "                if (face_recognition.compare_faces([face_encoder], cropped_encoding, tolerance=0.7)[0]):\n",
        "                    frameName = pathOut + filename[0:-4] + \"-face-cropped\" + \".jpg\"\n",
        "                    cropped_face = cv2.cvtColor(cropped_face, cv2.COLOR_BGR2RGB)\n",
        "                    cv2.imwrite(frameName, cropped_face)     # save cropped as JPEG file\n",
        "\n",
        "                    if mode == 'test':\n",
        "                      h, w, c = cropped_face.shape\n",
        "                      f = open(pathOut + \"frame_list.txt\", \"a\")\n",
        "                      f.write(\"%s, %d, %d, %d, %d, %d, %d\\n\" % (filename[5:-4], top, right, bottom, left, h, w))\n",
        "                      f.close()\n",
        "\n",
        "\n",
        "                    # print(filename[0:-4] + \"-face-cropped\" + \".jpg\")\n",
        "                    count += 1\n",
        "\n",
        "    # print(\"Cropped \" + str(count) + \" out of \" + (frame_count_compute))"
      ],
      "id": "eNhUyuq4lKvB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPHo4CLglMTt"
      },
      "source": [
        "import zipfile\n",
        "    \n",
        "def zipdir(path, ziph):\n",
        "    # ziph is zipfile handle\n",
        "    for root, dirs, files in os.walk(path):\n",
        "        for file in files:\n",
        "            ziph.write(os.path.join(root, file), \n",
        "                       os.path.relpath(os.path.join(root, file), \n",
        "                                       os.path.join(path, '..')))"
      ],
      "id": "JPHo4CLglMTt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "included-hospital",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0162ec8e-9fa6-401d-d298-60a955189930"
      },
      "source": [
        "# image = face_recognition.load_image_file(\"drive/MyDrive/UMDCP/CMSC/CMSC472/JohnOliver1.jpg\")\n",
        "# oliver_encoding = face_recognition.face_encodings(image)[0]\n",
        "\n",
        "# image2 = face_recognition.load_image_file(\"drive/MyDrive/UMDCP/CMSC/CMSC472/JohnOliver1-cropped/frame0103.jpg\")\n",
        "# unknown_encoding = face_recognition.face_encodings(image2)[0]\n",
        "\n",
        "# results = face_recognition.compare_faces([oliver_encoding], unknown_encoding)\n",
        "# print(results)"
      ],
      "id": "included-hospital",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[True]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "standard-antenna",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ff7eae0-607a-4bef-b4aa-e9b96f1fd8b3"
      },
      "source": [
        "# image = face_recognition.load_image_file(\"drive/MyDrive/UMDCP/CMSC/CMSC472/JohnOliver1.jpg\")\n",
        "# johnny_encoding = face_recognition.face_encodings(image)[0]\n",
        "# singleFaceExtracter('drive/MyDrive/UMDCP/CMSC/CMSC472/JohnOliver1-cropped/', johnny_encoding)"
      ],
      "id": "standard-antenna",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/UMDCP/CMSC/CMSC472/JohnOliver1-cropped-face-crop/\n",
            "frame0000-face-cropped.jpg\n",
            "frame0073.jpg\n",
            "frame0074.jpg\n",
            "frame0703-face-cropped.jpg\n",
            "frame1403-face-cropped.jpg\n",
            "frame1581.jpg\n",
            "frame1584.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fitting-letters",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9751c15-9cbb-4007-ff0c-9e2c28ad1309"
      },
      "source": [
        "\"\"\" --------------------------- MAIN --------------------------- \"\"\"\n",
        "train_file = \"Jimmy Fallon.mp4\"\n",
        "train_encoding_frame_number = 45\n",
        "# test_file = \"jimmy.mp4\"\n",
        "# test_encoding_frame_number = 22\n",
        "input_directory = \"drive/MyDrive/UMDCP/CMSC/CMSC472\"\n",
        "output_directory = \"drive/MyDrive/UMDCP/CMSC/CMSC472\"\n",
        "\n",
        "# extractImages(train_file, input_directory, output_directory, frame_every=1)\n",
        "print(\"Done extracting training frames\")\n",
        "\n",
        "image = face_recognition.load_image_file(output_directory + \"/\" + train_file[0:-4] + \"/frame%04d.jpg\" % (train_encoding_frame_number))\n",
        "jimmy_encoding = face_recognition.face_encodings(image)[0]\n",
        "singleFaceExtracterWithExtraPixels(train_file[0:-4] + \"/\", output_directory, jimmy_encoding, padding=0, batch_size=4)\n",
        "print(\"Done face cropping training frames\")\n",
        "\n",
        "# extractImages(test_file, input_directory, output_directory)\n",
        "# print(\"Done extracting testing frames\")\n",
        "\n",
        "# image = face_recognition.load_image_file(output_directory + \"/\" + test_file[0:-4] + \"/frame%05d.jpg\" % (test_encoding_frame_number))\n",
        "# jimmy_encoding = face_recognition.face_encodings(image)[0]\n",
        "# singleFaceExtracterWithExtraPixels(test_file[0:-4] + \"/\", output_directory, jimmy_encoding, padding=0, mode='test', batch_size=4)\n",
        "# print(\"Done face cropping testing frames\")\n",
        "\n",
        "print(\"Output path: \" + output_directory)\n",
        "# print(num_images('drive/MyDrive/UMDCP/CMSC/CMSC472/'))\n",
        "print(\"!---------------------------COMPLETE!---------------------------!\")"
      ],
      "id": "fitting-letters",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done extracting training frames\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/450 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "drive/MyDrive/UMDCP/CMSC/CMSC472/Jimmy Fallon-face-crop/\n",
            "1798\n",
            "4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  6%|▌         | 25/450 [00:20<06:04,  1.17it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "frame0099.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  8%|▊         | 34/450 [00:27<05:26,  1.27it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "frame0133.jpg\n",
            "frame0134.jpg\n",
            "frame0135.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  8%|▊         | 35/450 [00:28<05:20,  1.30it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "frame0136.jpg\n",
            "frame0137.jpg\n",
            "frame0138.jpg\n",
            "frame0139.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  8%|▊         | 36/450 [00:28<05:17,  1.31it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "frame0140.jpg\n",
            "frame0141.jpg\n",
            "frame0142.jpg\n",
            "frame0143.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  8%|▊         | 37/450 [00:29<05:12,  1.32it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "frame0144.jpg\n",
            "frame0145.jpg\n",
            "frame0146.jpg\n",
            "frame0147.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  8%|▊         | 38/450 [00:30<05:09,  1.33it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "frame0148.jpg\n",
            "frame0149.jpg\n",
            "frame0150.jpg\n",
            "frame0151.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  9%|▊         | 39/450 [00:30<05:04,  1.35it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "frame0152.jpg\n",
            "frame0153.jpg\n",
            "frame0154.jpg\n",
            "frame0155.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 20%|██        | 92/450 [01:13<04:41,  1.27it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "frame0366.jpg\n",
            "frame0368.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 21%|██        | 93/450 [01:14<04:53,  1.22it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "frame0371.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 21%|██        | 94/450 [01:14<04:44,  1.25it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "frame0372.jpg\n",
            "frame0373.jpg\n",
            "frame0374.jpg\n",
            "frame0375.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 21%|██        | 95/450 [01:15<04:34,  1.29it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "frame0376.jpg\n",
            "frame0377.jpg\n",
            "frame0378.jpg\n",
            "frame0379.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 21%|██▏       | 96/450 [01:16<04:26,  1.33it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "frame0380.jpg\n",
            "frame0381.jpg\n",
            "frame0382.jpg\n",
            "frame0383.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 22%|██▏       | 97/450 [01:17<04:21,  1.35it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "frame0384.jpg\n",
            "frame0385.jpg\n",
            "frame0386.jpg\n",
            "frame0387.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 22%|██▏       | 98/450 [01:17<04:21,  1.35it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "frame0388.jpg\n",
            "frame0390.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 22%|██▏       | 99/450 [01:18<04:20,  1.35it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "frame0394.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 114/450 [01:30<04:27,  1.26it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "frame0454.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 63%|██████▎   | 284/450 [03:47<02:16,  1.22it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "frame1135.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 64%|██████▍   | 287/450 [03:49<02:08,  1.27it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "frame1144.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 64%|██████▍   | 288/450 [03:50<02:05,  1.29it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "frame1148.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 66%|██████▌   | 297/450 [03:57<02:03,  1.24it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "frame1185.jpg\n",
            "frame1186.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 66%|██████▌   | 298/450 [03:58<02:00,  1.26it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "frame1190.jpg\n",
            "frame1191.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 66%|██████▋   | 299/450 [03:58<01:58,  1.28it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "frame1193.jpg\n",
            "frame1194.jpg\n",
            "frame1195.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 300/450 [03:59<01:55,  1.29it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "frame1196.jpg\n",
            "frame1197.jpg\n",
            "frame1198.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 70%|███████   | 316/450 [04:12<01:49,  1.22it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "frame1263.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 450/450 [05:59<00:00,  1.25it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Done face cropping training frames\n",
            "Output path: drive/MyDrive/UMDCP/CMSC/CMSC472\n",
            "!---------------------------COMPLETE!---------------------------!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcmfHFwUmK8Z"
      },
      "source": [
        ""
      ],
      "id": "LcmfHFwUmK8Z",
      "execution_count": null,
      "outputs": []
    }
  ]
}